## ğŸ‘ï¸ GuardianEye â€“ Smart Eyewear for the Visually Impaired

> An AI-powered, sensor-integrated wearable device for obstacle detection, text recognition, navigation, and real-time assistanceâ€”built to empower visually impaired individuals with safe, independent mobility.

---

![GuardianEye Banner](https://img.shields.io/badge/Smart-Wearable-brightgreen) ![License](https://img.shields.io/badge/license-MIT-blue) ![Status](https://img.shields.io/badge/status-Prototype-orange)

## ğŸ” Overview

**GuardianEye** is a multi-sensory smart eyewear system designed to assist visually impaired individuals in navigating their surroundings confidently and independently. By combining advanced **AI**, **computer vision**, and **sensor fusion**, the device offers:

- Real-time **obstacle detection**
- **Currency note recognition**
- **Printed text reading** via OCR
- **Multi-language voice feedback**
- Location tracking for caregivers
- Hands-free voice command control
- **Emergency alert** system with haptic and audio feedback

---

## ğŸš€ Key Features

| Feature                        | Description                                                                 |
|-------------------------------|-----------------------------------------------------------------------------|
| ğŸ›£ï¸ Real-Time Obstacle Detection | Detects and classifies static/dynamic obstacles using **LiDAR + YOLO**     |
| ğŸ’¬ Multi-Language Voice Output | NLP-based output in **multiple languages** for localized interaction        |
| ğŸ“· Optical Character Recognition (OCR) | Reads text from newspapers, signboards, etc., and converts to speech |
| ğŸ™ï¸ Voice Command System        | Microphone-powered **hands-free interaction** via natural language          |
| ğŸ’¸ Currency Note Detection     | Identifies denomination using computer vision to prevent fraud             |
| ğŸ§­ GPS Location Tracking       | Enables **family members** to track userâ€™s location remotely                |
| ğŸ¤– Person & Object Recognition | Recognizes known individuals and frequently seen objects                    |
| ğŸ“³ Haptic Feedback             | Vibrates for obstacle alerts, turns, or important environmental cues       |
| ğŸš¨ Emergency Beep Alert       | Loud **beeping sound** triggers when immediate danger is detected          |

---

## ğŸ§  Technologies Used

- **ğŸ§  AI Models:** YOLOv8 (Object Detection), Tesseract (OCR), NLP (Speech-to-Text / Text-to-Speech)
- **ğŸŒ Communication:** Bluetooth Low Energy (BLE)
- **ğŸ”Š Audio Feedback:** Bone conduction speakers
- **ğŸ“· Sensors:** LiDAR, Pi camera, GPS
- **ğŸ“¦ Hardware Platform:** Microcontroller (Raspberry Pi), Rechargeable battery, Microphone

---

## ğŸ§° System Architecture

<img width="1076" height="1080" alt="Sitemap" src="https://github.com/user-attachments/assets/54c36cd9-ad2f-463c-971a-5022eb1b32ba" />
![WhatsApp Image 2025-07-19 at 22 58 16_b30fc57b](https://github.com/user-attachments/assets/534d884c-b585-4151-a018-d6377e279c50)


## ğŸ¯ Use Cases

- Navigate urban streets, stairs, and corridors
- Recognize people at work or home
- Read public signs or packaging labels
- Detect currency during monetary exchange
- Alert surroundings in case of emergencies
- Stay connected with caregivers for safety

---

## ğŸ“· Media & Demos

> Coming Soon: Demo Video
>
> <img width="712" height="596" alt="image" src="https://github.com/user-attachments/assets/c3f15b91-6b9d-420d-8c33-24f2eec935c5" />
<img width="712" height="596" alt="image" src="https://github.com/user-attachments/assets/26563abc-85df-4c30-89de-47c81b6894c4" />



- âœ… Real-time object detection
- âœ… Text-to-speech conversion of printed material
- âœ… GPS tracking dashboard for caregivers
- âœ… Voice-command feature demo

---

## ğŸ§ª Project Status

- [x] Research and literature review
- [x] Hardware component selection
- [x] AI module prototyping (YOLO + OCR)
- [x] NLP-based multi-language system
- [ ] Integration & Testing
- [ ] Real-world trials with visually impaired users
- [ ] Final production and optimization

---


## ğŸ‘¨â€ğŸ’» Contributors

- **Anirudh Garg** â€“ Computer vision(Team Lead)
- **Aaradhya Sharma** â€“ Computer vision 
- **Abhiroop Singh** â€“ IoT 
- **Rajveer Singh** â€“ Speech Processing, Documentation  
- **Bhavneet Kaur** â€“ NLP, Speech Processing 

---

## ğŸ“œ License

This project is licensed under the [MIT License](LICENSE).

---

## ğŸ¤ Support & Contact

Have feedback, ideas, or want to collaborate? Reach out at:

ğŸ“§ agarg3_be22@thapar.edu  
---

> _"Letâ€™s build a world where everyone can see possibilitiesâ€”even without sight."_ ğŸŒ
